{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPe0R6RPcOGVNJDe5Q58bDx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTLzDTQbWwvk","executionInfo":{"status":"ok","timestamp":1748865939116,"user_tz":-330,"elapsed":7963,"user":{"displayName":"Prajnavi","userId":"02418603915941783168"}},"outputId":"06082967-7b6f-4fc8-9654-01acdd0ce468"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import cv2\n","import os\n","import numpy as np\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import normalize\n","from skimage.feature import local_binary_pattern\n","import joblib\n","\n","def split_image(image, patch_size=400, overlap=0.5):\n","    height, width = image.shape[:2]\n","    step = int(patch_size * (1 - overlap))\n","    patches, coordinates = [], []\n","    for y in range(0, height - patch_size + 1, step):\n","        for x in range(0, width - patch_size + 1, step):\n","            patches.append(image[y:y + patch_size, x:x + patch_size])\n","            coordinates.append((x, y, x + patch_size, y + patch_size))\n","    return patches, coordinates\n","\n","def extract_features(image):\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    resized = cv2.resize(gray, (128, 128))\n","    lbp = local_binary_pattern(resized, 8, 1, method='uniform')\n","    hist_lbp, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 9))\n","    hist_lbp = hist_lbp.astype(\"float\")\n","    hist_lbp /= (hist_lbp.sum() + 1e-7)\n","\n","    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","    hist_h = cv2.calcHist([hsv], [0], None, [8], [0, 180])\n","    hist_s = cv2.calcHist([hsv], [1], None, [8], [0, 256])\n","    hist_v = cv2.calcHist([hsv], [2], None, [8], [0, 256])\n","    hist_color = np.concatenate((hist_h, hist_s, hist_v)).flatten()\n","    hist_color = normalize(hist_color.reshape(1, -1))[0]\n","\n","    return np.concatenate([hist_lbp, hist_color])\n","\n","def train_svm(reference_folder):\n","    features, labels = [], []\n","    for label in ['positive', 'negative']:\n","        folder = os.path.join(reference_folder, label)\n","        for file in os.listdir(folder):\n","            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n","                img = cv2.imread(os.path.join(folder, file))\n","                if img is not None:\n","                    features.append(extract_features(img))\n","                    labels.append(1 if label == 'positive' else 0)\n","    clf = SVC(kernel='linear', probability=True)\n","    clf.fit(features, labels)\n","    joblib.dump(clf, 'arecanut_svm_model.pkl')\n","    return clf\n","\n","def detect_arecanut(image, clf, patch_size=400, overlap=0.5, threshold=0.5):\n","    patches, coords = split_image(image, patch_size, overlap)\n","    boxes = []\n","    for patch, coord in zip(patches, coords):\n","        feat = extract_features(patch)\n","        prob = clf.predict_proba([feat])[0][1]\n","        if prob >= threshold:\n","            boxes.append(coord)\n","    return boxes\n","\n","def compute_iou(box1, box2):\n","    x1, y1 = max(box1[0], box2[0]), max(box1[1], box2[1])\n","    x2, y2 = min(box1[2], box2[2]), min(box1[3], box2[3])\n","    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n","    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n","    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n","    return inter_area / (area1 + area2 - inter_area + 1e-7)\n","\n","def merge_boxes(boxes, iou_threshold=0.3):\n","    merged = []\n","    while boxes:\n","        base = boxes.pop(0)\n","        overlapping = [b for b in boxes if compute_iou(base, b) > iou_threshold]\n","        for b in overlapping:\n","            boxes.remove(b)\n","        all_boxes = [base] + overlapping\n","        x1 = min(b[0] for b in all_boxes)\n","        y1 = min(b[1] for b in all_boxes)\n","        x2 = max(b[2] for b in all_boxes)\n","        y2 = max(b[3] for b in all_boxes)\n","        merged.append((x1, y1, x2, y2))\n","    return merged\n","\n","def save_results(image, boxes, image_name, output_image_folder, output_label_folder):\n","    os.makedirs(output_image_folder, exist_ok=True)\n","    os.makedirs(output_label_folder, exist_ok=True)\n","\n","    for box in boxes:\n","        x1, y1, x2, y2 = box\n","        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","\n","    cv2.imwrite(os.path.join(output_image_folder, image_name), image)\n","\n","    h, w = image.shape[:2]\n","    label_path = os.path.join(output_label_folder, os.path.splitext(image_name)[0] + '.txt')\n","    with open(label_path, 'w') as f:\n","        for x1, y1, x2, y2 in boxes:\n","            x_center = ((x1 + x2) / 2) / w\n","            y_center = ((y1 + y2) / 2) / h\n","            bw = (x2 - x1) / w\n","            bh = (y2 - y1) / h\n","            f.write(f\"0 {x_center:.6f} {y_center:.6f} {bw:.6f} {bh:.6f}\\n\")\n","\n","\n"],"metadata":{"id":"rriLVEpTW3bY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    # Train once and save model\n","    reference_images = \"/content/drive/MyDrive/Arecanut_Detection_with_ML/Arecanut_Detection/Model_Statistical_Detection/reference_images\"\n","    clf = train_svm(reference_images)  # contains 'positive' and 'negative' subfolders\n","\n","    # Input and output paths\n","    input_image_folder = \"/content/drive/MyDrive/Arecanut_Detection_with_ML/Arecanut_Detection/Model_Statistical_Detection/test_images\"  # your input folder path\n","    output_image_folder = \"/content/drive/MyDrive/Arecanut_Detection_with_ML/Arecanut_Detection/Model_Statistical_Detection/using_svm/output_images\"\n","    output_label_folder = \"/content/drive/MyDrive/Arecanut_Detection_with_ML/Arecanut_Detection/Model_Statistical_Detection/using_svm/output_labels\"\n","\n","    # Create output directories if they don't exist\n","    os.makedirs(output_image_folder, exist_ok=True)\n","    os.makedirs(output_label_folder, exist_ok=True)\n","\n","    # Process each image in the input folder\n","    for img_name in os.listdir(input_image_folder):\n","        img_path = os.path.join(input_image_folder, img_name)\n","\n","        # Skip if not an image file\n","        if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            continue\n","\n","        # Load image and detect arecanut\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            print(f\"Could not read image: {img_path}\")\n","            continue\n","\n","        boxes = detect_arecanut(img, clf)\n","        merged_boxes = merge_boxes(boxes)\n","\n","        # Save bounding box results and labels\n","        save_results(img, merged_boxes, img_name, output_image_folder, output_label_folder)\n","        print(f\"Processed image: {img_name}\")\n","\n","        print(f\"Successfully processed {img_name}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBY1EmVwrYeV","executionInfo":{"status":"ok","timestamp":1748866018478,"user_tz":-330,"elapsed":57247,"user":{"displayName":"Prajnavi","userId":"02418603915941783168"}},"outputId":"9d7c5374-35c4-4fae-ea27-8ce941be8d3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed image: image3.jpg\n","Successfully processed image3.jpg\n","Processed image: image1.jpg\n","Successfully processed image1.jpg\n","Processed image: image2.jpg\n","Successfully processed image2.jpg\n","Processed image: image4.jpg\n","Successfully processed image4.jpg\n","Processed image: image5.jpg\n","Successfully processed image5.jpg\n","Processed image: image6.jpg\n","Successfully processed image6.jpg\n","Processed image: image7.jpg\n","Successfully processed image7.jpg\n","Processed image: image8.jpg\n","Successfully processed image8.jpg\n","Processed image: image-255.jpg\n","Successfully processed image-255.jpg\n","Processed image: image-108.jpg\n","Successfully processed image-108.jpg\n","Processed image: image-1.jpg\n","Successfully processed image-1.jpg\n","Processed image: image-103.jpg\n","Successfully processed image-103.jpg\n","Processed image: image-178.jpg\n","Successfully processed image-178.jpg\n","Processed image: image-71.jpg\n","Successfully processed image-71.jpg\n","Processed image: image-131.jpg\n","Successfully processed image-131.jpg\n","Processed image: image-322.jpg\n","Successfully processed image-322.jpg\n","Processed image: image-134.jpg\n","Successfully processed image-134.jpg\n","Processed image: image-162.jpg\n","Successfully processed image-162.jpg\n","Processed image: image-179.jpg\n","Successfully processed image-179.jpg\n","Processed image: image-317.jpg\n","Successfully processed image-317.jpg\n","Processed image: image-170.jpg\n","Successfully processed image-170.jpg\n","Processed image: image-172.jpg\n","Successfully processed image-172.jpg\n","Processed image: image-164.jpg\n","Successfully processed image-164.jpg\n","Processed image: image-117.jpg\n","Successfully processed image-117.jpg\n","Processed image: image-73.jpg\n","Successfully processed image-73.jpg\n","Processed image: image-175.jpg\n","Successfully processed image-175.jpg\n","Processed image: image-174.jpg\n","Successfully processed image-174.jpg\n","Processed image: image-173.jpg\n","Successfully processed image-173.jpg\n","Processed image: image-324.jpg\n","Successfully processed image-324.jpg\n","Processed image: image-320.jpg\n","Successfully processed image-320.jpg\n","Processed image: image-302.jpg\n","Successfully processed image-302.jpg\n","Processed image: image-315.jpg\n","Successfully processed image-315.jpg\n","Processed image: image-132.jpg\n","Successfully processed image-132.jpg\n","Processed image: image-53.jpg\n","Successfully processed image-53.jpg\n","Processed image: image-159.jpg\n","Successfully processed image-159.jpg\n","Processed image: image-360.jpg\n","Successfully processed image-360.jpg\n","Processed image: image-374.jpg\n","Successfully processed image-374.jpg\n","Processed image: image-357.jpg\n","Successfully processed image-357.jpg\n","Processed image: image-84.jpg\n","Successfully processed image-84.jpg\n","Processed image: image-30.jpg\n","Successfully processed image-30.jpg\n","Processed image: image-28.jpg\n","Successfully processed image-28.jpg\n","Processed image: image-24.jpg\n","Successfully processed image-24.jpg\n","Processed image: image-102.jpg\n","Successfully processed image-102.jpg\n","Processed image: image-79.jpg\n","Successfully processed image-79.jpg\n","Processed image: image-353.jpg\n","Successfully processed image-353.jpg\n","Processed image: image-390.jpg\n","Successfully processed image-390.jpg\n","Processed image: image-350.jpg\n","Successfully processed image-350.jpg\n","Processed image: image-66.jpg\n","Successfully processed image-66.jpg\n","Processed image: image-15.jpg\n","Successfully processed image-15.jpg\n","Processed image: image-23.jpg\n","Successfully processed image-23.jpg\n","Processed image: image-309.jpg\n","Successfully processed image-309.jpg\n","Processed image: image-96.jpg\n","Successfully processed image-96.jpg\n","Processed image: image-11.jpg\n","Successfully processed image-11.jpg\n","Processed image: image-29.jpg\n","Successfully processed image-29.jpg\n","Processed image: image-168.jpg\n","Successfully processed image-168.jpg\n","Processed image: image-27.jpg\n","Successfully processed image-27.jpg\n","Processed image: image-383.jpg\n","Successfully processed image-383.jpg\n","Processed image: image-31.jpg\n","Successfully processed image-31.jpg\n","Processed image: image-32.jpg\n","Successfully processed image-32.jpg\n","Processed image: image-167.jpg\n","Successfully processed image-167.jpg\n","Processed image: image-80.jpg\n","Successfully processed image-80.jpg\n","Processed image: image-135.jpg\n","Successfully processed image-135.jpg\n","Processed image: image-81.jpg\n","Successfully processed image-81.jpg\n","Processed image: image-351.jpg\n","Successfully processed image-351.jpg\n","Processed image: image-25.jpg\n","Successfully processed image-25.jpg\n","Processed image: image-85.jpg\n","Successfully processed image-85.jpg\n","Processed image: image-147.jpg\n","Successfully processed image-147.jpg\n","Processed image: image-101.jpg\n","Successfully processed image-101.jpg\n","Processed image: image-319.jpg\n","Successfully processed image-319.jpg\n","Processed image: image-82.jpg\n","Successfully processed image-82.jpg\n","Processed image: image-67.jpg\n","Successfully processed image-67.jpg\n","Processed image: image-26.jpg\n","Successfully processed image-26.jpg\n","Processed image: image-145.jpg\n","Successfully processed image-145.jpg\n","Processed image: image-382.jpg\n","Successfully processed image-382.jpg\n","Processed image: image-331.jpg\n","Successfully processed image-331.jpg\n","Processed image: image-98.jpg\n","Successfully processed image-98.jpg\n","Processed image: image-22.jpg\n","Successfully processed image-22.jpg\n","Processed image: image-146.jpg\n","Successfully processed image-146.jpg\n","Processed image: image-141.jpg\n","Successfully processed image-141.jpg\n","Processed image: image-376.jpg\n","Successfully processed image-376.jpg\n","Processed image: image-70.jpg\n","Successfully processed image-70.jpg\n","Processed image: image-139.jpg\n","Successfully processed image-139.jpg\n","Processed image: image-78.jpg\n","Successfully processed image-78.jpg\n","Processed image: image-69.jpg\n","Successfully processed image-69.jpg\n","Processed image: image-33.jpg\n","Successfully processed image-33.jpg\n","Processed image: image-100.jpg\n","Successfully processed image-100.jpg\n","Processed image: image-20.jpg\n","Successfully processed image-20.jpg\n","Processed image: image-313.jpg\n","Successfully processed image-313.jpg\n","Processed image: image-140.jpg\n","Successfully processed image-140.jpg\n","Processed image: image-312.jpg\n","Successfully processed image-312.jpg\n","Processed image: image-41.jpg\n","Successfully processed image-41.jpg\n","Processed image: image-55.jpg\n","Successfully processed image-55.jpg\n","Processed image: image-50.jpg\n","Successfully processed image-50.jpg\n","Processed image: image-311.jpg\n","Successfully processed image-311.jpg\n","Processed image: image-126.jpg\n","Successfully processed image-126.jpg\n","Processed image: image-348.jpg\n","Successfully processed image-348.jpg\n","Processed image: image-86.jpg\n","Successfully processed image-86.jpg\n","Processed image: image-19.jpg\n","Successfully processed image-19.jpg\n","Processed image: image-142.jpg\n","Successfully processed image-142.jpg\n","Processed image: image-38.jpg\n","Successfully processed image-38.jpg\n","Processed image: image-345.jpg\n","Successfully processed image-345.jpg\n","Processed image: image-6.jpg\n","Successfully processed image-6.jpg\n","Processed image: image-346 (1).jpg\n","Successfully processed image-346 (1).jpg\n","Processed image: image-389.jpg\n","Successfully processed image-389.jpg\n","Processed image: image-18.jpg\n","Successfully processed image-18.jpg\n","Processed image: image-127.jpg\n","Successfully processed image-127.jpg\n","Processed image: image-119.jpg\n","Successfully processed image-119.jpg\n","Processed image: image-308.jpg\n","Successfully processed image-308.jpg\n","Processed image: image-125.jpg\n","Successfully processed image-125.jpg\n","Processed image: image-346.jpg\n","Successfully processed image-346.jpg\n","Processed image: image-304.jpg\n","Successfully processed image-304.jpg\n","Processed image: image-347.jpg\n","Successfully processed image-347.jpg\n","Processed image: image-342.jpg\n","Successfully processed image-342.jpg\n","Processed image: image-344.jpg\n","Successfully processed image-344.jpg\n","Processed image: image-47.jpg\n","Successfully processed image-47.jpg\n","Processed image: image-49.jpg\n","Successfully processed image-49.jpg\n","Processed image: image-17.jpg\n","Successfully processed image-17.jpg\n","Processed image: image-129.jpg\n","Successfully processed image-129.jpg\n","Processed image: image-318.jpg\n","Successfully processed image-318.jpg\n","Processed image: image-7.jpg\n","Successfully processed image-7.jpg\n","Processed image: image-51.jpg\n","Successfully processed image-51.jpg\n","Processed image: image-116.jpg\n","Successfully processed image-116.jpg\n","Processed image: image-122.jpg\n","Successfully processed image-122.jpg\n","Processed image: image-4.jpg\n","Successfully processed image-4.jpg\n","Processed image: image-46.jpg\n","Successfully processed image-46.jpg\n","Processed image: image-35.jpg\n","Successfully processed image-35.jpg\n","Processed image: image-45.jpg\n","Successfully processed image-45.jpg\n","Processed image: image-43.jpg\n","Successfully processed image-43.jpg\n","Processed image: image-44.jpg\n","Successfully processed image-44.jpg\n","Processed image: image-112.jpg\n","Successfully processed image-112.jpg\n"]}]},{"cell_type":"code","source":["import cv2\n","import os\n","import numpy as np\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import normalize\n","from skimage.feature import local_binary_pattern\n","import joblib\n","\n","def split_image(image, patch_size=400, overlap=0.5):\n","    height, width = image.shape[:2]\n","    step = int(patch_size * (1 - overlap))\n","    patches, coordinates = [], []\n","    for y in range(0, height - patch_size + 1, step):\n","        for x in range(0, width - patch_size + 1, step):\n","            patches.append(image[y:y + patch_size, x:x + patch_size])\n","            coordinates.append((x, y, x + patch_size, y + patch_size))\n","    return patches, coordinates\n","\n","def extract_features(image):\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    resized = cv2.resize(gray, (128, 128))\n","    lbp = local_binary_pattern(resized, 8, 1, method='uniform')\n","    hist_lbp, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 9))\n","    hist_lbp = hist_lbp.astype(\"float\")\n","    hist_lbp /= (hist_lbp.sum() + 1e-7)\n","\n","    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","    hist_h = cv2.calcHist([hsv], [0], None, [8], [0, 180])\n","    hist_s = cv2.calcHist([hsv], [1], None, [8], [0, 256])\n","    hist_v = cv2.calcHist([hsv], [2], None, [8], [0, 256])\n","    hist_color = np.concatenate((hist_h, hist_s, hist_v)).flatten()\n","    hist_color = normalize(hist_color.reshape(1, -1))[0]\n","\n","    return np.concatenate([hist_lbp, hist_color])\n","\n","def train_rf(reference_folder):\n","    features, labels = [], []\n","    for label in ['positive', 'negative']:\n","        folder = os.path.join(reference_folder, label)\n","        for file in os.listdir(folder):\n","            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n","                img = cv2.imread(os.path.join(folder, file))\n","                if img is not None:\n","                    features.append(extract_features(img))\n","                    labels.append(1 if label == 'positive' else 0)\n","    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n","    clf.fit(features, labels)\n","    joblib.dump(clf, 'arecanut_rf_model.pkl')\n","    return clf\n","\n","def detect_arecanut(image, clf, patch_size=400, overlap=0.5, threshold=0.5):\n","    patches, coords = split_image(image, patch_size, overlap)\n","    boxes = []\n","    for patch, coord in zip(patches, coords):\n","        feat = extract_features(patch)\n","        prob = clf.predict_proba([feat])[0][1]\n","        if prob >= threshold:\n","            boxes.append(coord)\n","    return boxes\n","\n","def compute_iou(box1, box2):\n","    x1, y1 = max(box1[0], box2[0]), max(box1[1], box2[1])\n","    x2, y2 = min(box1[2], box2[2]), min(box1[3], box2[3])\n","    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n","    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n","    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n","    return inter_area / (area1 + area2 - inter_area + 1e-7)\n","\n","def merge_boxes(boxes, iou_threshold=0.3):\n","    merged = []\n","    while boxes:\n","        base = boxes.pop(0)\n","        overlapping = [b for b in boxes if compute_iou(base, b) > iou_threshold]\n","        for b in overlapping:\n","            boxes.remove(b)\n","        all_boxes = [base] + overlapping\n","        x1 = min(b[0] for b in all_boxes)\n","        y1 = min(b[1] for b in all_boxes)\n","        x2 = max(b[2] for b in all_boxes)\n","        y2 = max(b[3] for b in all_boxes)\n","        merged.append((x1, y1, x2, y2))\n","    return merged\n","\n","def save_results(image, boxes, image_name, output_image_folder, output_label_folder):\n","    os.makedirs(output_image_folder, exist_ok=True)\n","    os.makedirs(output_label_folder, exist_ok=True)\n","\n","    for box in boxes:\n","        x1, y1, x2, y2 = box\n","        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","\n","    cv2.imwrite(os.path.join(output_image_folder, image_name), image)\n","\n","    h, w = image.shape[:2]\n","    label_path = os.path.join(output_label_folder, os.path.splitext(image_name)[0] + '.txt')\n","    with open(label_path, 'w') as f:\n","        for x1, y1, x2, y2 in boxes:\n","            x_center = ((x1 + x2) / 2) / w\n","            y_center = ((y1 + y2) / 2) / h\n","            bw = (x2 - x1) / w\n","            bh = (y2 - y1) / h\n","            f.write(f\"0 {x_center:.6f} {y_center:.6f} {bw:.6f} {bh:.6f}\\n\")\n"],"metadata":{"id":"oSIlcsaWnOln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    # Train once and save model\n","    reference_images = \"/content/drive/MyDrive/Arecanut_Detection_with_ML/Arecanut_Detection/Model_Statistical_Detection/reference_images\"\n","    clf = train_svm(reference_images)  # contains 'positive' and 'negative' subfolders\n","\n","    # Input and output paths\n","    input_image_folder = \"/content/drive/MyDrive/Arecanut_Detection_with_ML/Arecanut_Detection/Model_Statistical_Detection/test_images\"\n","    output_image_folder = \"/content/drive/MyDrive/Arecanut_Detection_with_ML/Arecanut_Detection/Model_Statistical_Detection/using_random_forest/output_images\"\n","    output_label_folder = \"/content/drive/MyDrive/Arecanut_Detection_with_ML/Arecanut_Detection/Model_Statistical_Detection/using_random_forest/output_labels\"\n","\n","    # Create output directories if they don't exist\n","    os.makedirs(output_image_folder, exist_ok=True)\n","    os.makedirs(output_label_folder, exist_ok=True)\n","\n","    # Process each image in the input folder\n","    for img_name in os.listdir(input_image_folder):\n","        img_path = os.path.join(input_image_folder, img_name)\n","\n","        # Skip if not an image file\n","        if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            continue\n","\n","        # Load image and detect arecanut\n","        try:\n","            img = cv2.imread(img_path)\n","            if img is None:\n","                print(f\"Could not read image: {img_path}\")\n","                continue\n","\n","            boxes = detect_arecanut(img, clf)\n","            merged_boxes = merge_boxes(boxes)\n","\n","            # Save bounding box results and labels\n","            save_results(img, merged_boxes, img_name, output_image_folder, output_label_folder)\n","            print(f\"Processed image: {img_name}\")\n","\n","            print(f\"Successfully processed {img_name}\")\n","\n","        except Exception as e:\n","            print(f\"Error processing {img_name}: {str(e)}\")"],"metadata":{"id":"S50lKONmnRyQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748866048114,"user_tz":-330,"elapsed":29597,"user":{"displayName":"Prajnavi","userId":"02418603915941783168"}},"outputId":"9475d95c-a8d8-4cdc-f64d-0f53e240c7ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed image: image3.jpg\n","Successfully processed image3.jpg\n","Processed image: image1.jpg\n","Successfully processed image1.jpg\n","Processed image: image2.jpg\n","Successfully processed image2.jpg\n","Processed image: image4.jpg\n","Successfully processed image4.jpg\n","Processed image: image5.jpg\n","Successfully processed image5.jpg\n","Processed image: image6.jpg\n","Successfully processed image6.jpg\n","Processed image: image7.jpg\n","Successfully processed image7.jpg\n","Processed image: image8.jpg\n","Successfully processed image8.jpg\n","Processed image: image-255.jpg\n","Successfully processed image-255.jpg\n","Processed image: image-108.jpg\n","Successfully processed image-108.jpg\n","Processed image: image-1.jpg\n","Successfully processed image-1.jpg\n","Processed image: image-103.jpg\n","Successfully processed image-103.jpg\n","Processed image: image-178.jpg\n","Successfully processed image-178.jpg\n","Processed image: image-71.jpg\n","Successfully processed image-71.jpg\n","Processed image: image-131.jpg\n","Successfully processed image-131.jpg\n","Processed image: image-322.jpg\n","Successfully processed image-322.jpg\n","Processed image: image-134.jpg\n","Successfully processed image-134.jpg\n","Processed image: image-162.jpg\n","Successfully processed image-162.jpg\n","Processed image: image-179.jpg\n","Successfully processed image-179.jpg\n","Processed image: image-317.jpg\n","Successfully processed image-317.jpg\n","Processed image: image-170.jpg\n","Successfully processed image-170.jpg\n","Processed image: image-172.jpg\n","Successfully processed image-172.jpg\n","Processed image: image-164.jpg\n","Successfully processed image-164.jpg\n","Processed image: image-117.jpg\n","Successfully processed image-117.jpg\n","Processed image: image-73.jpg\n","Successfully processed image-73.jpg\n","Processed image: image-175.jpg\n","Successfully processed image-175.jpg\n","Processed image: image-174.jpg\n","Successfully processed image-174.jpg\n","Processed image: image-173.jpg\n","Successfully processed image-173.jpg\n","Processed image: image-324.jpg\n","Successfully processed image-324.jpg\n","Processed image: image-320.jpg\n","Successfully processed image-320.jpg\n","Processed image: image-302.jpg\n","Successfully processed image-302.jpg\n","Processed image: image-315.jpg\n","Successfully processed image-315.jpg\n","Processed image: image-132.jpg\n","Successfully processed image-132.jpg\n","Processed image: image-53.jpg\n","Successfully processed image-53.jpg\n","Processed image: image-159.jpg\n","Successfully processed image-159.jpg\n","Processed image: image-360.jpg\n","Successfully processed image-360.jpg\n","Processed image: image-374.jpg\n","Successfully processed image-374.jpg\n","Processed image: image-357.jpg\n","Successfully processed image-357.jpg\n","Processed image: image-84.jpg\n","Successfully processed image-84.jpg\n","Processed image: image-30.jpg\n","Successfully processed image-30.jpg\n","Processed image: image-28.jpg\n","Successfully processed image-28.jpg\n","Processed image: image-24.jpg\n","Successfully processed image-24.jpg\n","Processed image: image-102.jpg\n","Successfully processed image-102.jpg\n","Processed image: image-79.jpg\n","Successfully processed image-79.jpg\n","Processed image: image-353.jpg\n","Successfully processed image-353.jpg\n","Processed image: image-390.jpg\n","Successfully processed image-390.jpg\n","Processed image: image-350.jpg\n","Successfully processed image-350.jpg\n","Processed image: image-66.jpg\n","Successfully processed image-66.jpg\n","Processed image: image-15.jpg\n","Successfully processed image-15.jpg\n","Processed image: image-23.jpg\n","Successfully processed image-23.jpg\n","Processed image: image-309.jpg\n","Successfully processed image-309.jpg\n","Processed image: image-96.jpg\n","Successfully processed image-96.jpg\n","Processed image: image-11.jpg\n","Successfully processed image-11.jpg\n","Processed image: image-29.jpg\n","Successfully processed image-29.jpg\n","Processed image: image-168.jpg\n","Successfully processed image-168.jpg\n","Processed image: image-27.jpg\n","Successfully processed image-27.jpg\n","Processed image: image-383.jpg\n","Successfully processed image-383.jpg\n","Processed image: image-31.jpg\n","Successfully processed image-31.jpg\n","Processed image: image-32.jpg\n","Successfully processed image-32.jpg\n","Processed image: image-167.jpg\n","Successfully processed image-167.jpg\n","Processed image: image-80.jpg\n","Successfully processed image-80.jpg\n","Processed image: image-135.jpg\n","Successfully processed image-135.jpg\n","Processed image: image-81.jpg\n","Successfully processed image-81.jpg\n","Processed image: image-351.jpg\n","Successfully processed image-351.jpg\n","Processed image: image-25.jpg\n","Successfully processed image-25.jpg\n","Processed image: image-85.jpg\n","Successfully processed image-85.jpg\n","Processed image: image-147.jpg\n","Successfully processed image-147.jpg\n","Processed image: image-101.jpg\n","Successfully processed image-101.jpg\n","Processed image: image-319.jpg\n","Successfully processed image-319.jpg\n","Processed image: image-82.jpg\n","Successfully processed image-82.jpg\n","Processed image: image-67.jpg\n","Successfully processed image-67.jpg\n","Processed image: image-26.jpg\n","Successfully processed image-26.jpg\n","Processed image: image-145.jpg\n","Successfully processed image-145.jpg\n","Processed image: image-382.jpg\n","Successfully processed image-382.jpg\n","Processed image: image-331.jpg\n","Successfully processed image-331.jpg\n","Processed image: image-98.jpg\n","Successfully processed image-98.jpg\n","Processed image: image-22.jpg\n","Successfully processed image-22.jpg\n","Processed image: image-146.jpg\n","Successfully processed image-146.jpg\n","Processed image: image-141.jpg\n","Successfully processed image-141.jpg\n","Processed image: image-376.jpg\n","Successfully processed image-376.jpg\n","Processed image: image-70.jpg\n","Successfully processed image-70.jpg\n","Processed image: image-139.jpg\n","Successfully processed image-139.jpg\n","Processed image: image-78.jpg\n","Successfully processed image-78.jpg\n","Processed image: image-69.jpg\n","Successfully processed image-69.jpg\n","Processed image: image-33.jpg\n","Successfully processed image-33.jpg\n","Processed image: image-100.jpg\n","Successfully processed image-100.jpg\n","Processed image: image-20.jpg\n","Successfully processed image-20.jpg\n","Processed image: image-313.jpg\n","Successfully processed image-313.jpg\n","Processed image: image-140.jpg\n","Successfully processed image-140.jpg\n","Processed image: image-312.jpg\n","Successfully processed image-312.jpg\n","Processed image: image-41.jpg\n","Successfully processed image-41.jpg\n","Processed image: image-55.jpg\n","Successfully processed image-55.jpg\n","Processed image: image-50.jpg\n","Successfully processed image-50.jpg\n","Processed image: image-311.jpg\n","Successfully processed image-311.jpg\n","Processed image: image-126.jpg\n","Successfully processed image-126.jpg\n","Processed image: image-348.jpg\n","Successfully processed image-348.jpg\n","Processed image: image-86.jpg\n","Successfully processed image-86.jpg\n","Processed image: image-19.jpg\n","Successfully processed image-19.jpg\n","Processed image: image-142.jpg\n","Successfully processed image-142.jpg\n","Processed image: image-38.jpg\n","Successfully processed image-38.jpg\n","Processed image: image-345.jpg\n","Successfully processed image-345.jpg\n","Processed image: image-6.jpg\n","Successfully processed image-6.jpg\n","Processed image: image-346 (1).jpg\n","Successfully processed image-346 (1).jpg\n","Processed image: image-389.jpg\n","Successfully processed image-389.jpg\n","Processed image: image-18.jpg\n","Successfully processed image-18.jpg\n","Processed image: image-127.jpg\n","Successfully processed image-127.jpg\n","Processed image: image-119.jpg\n","Successfully processed image-119.jpg\n","Processed image: image-308.jpg\n","Successfully processed image-308.jpg\n","Processed image: image-125.jpg\n","Successfully processed image-125.jpg\n","Processed image: image-346.jpg\n","Successfully processed image-346.jpg\n","Processed image: image-304.jpg\n","Successfully processed image-304.jpg\n","Processed image: image-347.jpg\n","Successfully processed image-347.jpg\n","Processed image: image-342.jpg\n","Successfully processed image-342.jpg\n","Processed image: image-344.jpg\n","Successfully processed image-344.jpg\n","Processed image: image-47.jpg\n","Successfully processed image-47.jpg\n","Processed image: image-49.jpg\n","Successfully processed image-49.jpg\n","Processed image: image-17.jpg\n","Successfully processed image-17.jpg\n","Processed image: image-129.jpg\n","Successfully processed image-129.jpg\n","Processed image: image-318.jpg\n","Successfully processed image-318.jpg\n","Processed image: image-7.jpg\n","Successfully processed image-7.jpg\n","Processed image: image-51.jpg\n","Successfully processed image-51.jpg\n","Processed image: image-116.jpg\n","Successfully processed image-116.jpg\n","Processed image: image-122.jpg\n","Successfully processed image-122.jpg\n","Processed image: image-4.jpg\n","Successfully processed image-4.jpg\n","Processed image: image-46.jpg\n","Successfully processed image-46.jpg\n","Processed image: image-35.jpg\n","Successfully processed image-35.jpg\n","Processed image: image-45.jpg\n","Successfully processed image-45.jpg\n","Processed image: image-43.jpg\n","Successfully processed image-43.jpg\n","Processed image: image-44.jpg\n","Successfully processed image-44.jpg\n","Processed image: image-112.jpg\n","Successfully processed image-112.jpg\n"]}]},{"cell_type":"code","source":["import cv2\n","import os\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import StandardScaler\n","from skimage.feature import local_binary_pattern\n","import joblib\n","from collections import defaultdict\n","\n","# Enhanced feature extraction\n","def extract_features(image):\n","    # Color features\n","    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","    hist_h = cv2.calcHist([hsv], [0], None, [16], [0, 180])\n","    hist_s = cv2.calcHist([hsv], [1], None, [16], [0, 256])\n","    hist_v = cv2.calcHist([hsv], [2], None, [16], [0, 256])\n","\n","    # Texture features\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    resized = cv2.resize(gray, (128, 128))\n","    lbp = local_binary_pattern(resized, 24, 3, method='uniform')\n","    hist_lbp, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 27), range=(0, 26))\n","\n","    # Edge features\n","    edges = cv2.Canny(gray, 100, 200)\n","    edge_density = np.sum(edges) / (edges.shape[0] * edges.shape[1])\n","\n","    # Combine all features\n","    features = np.concatenate([\n","        hist_h.flatten(),\n","        hist_s.flatten(),\n","        hist_v.flatten(),\n","        hist_lbp.flatten(),\n","        [edge_density]\n","    ])\n","\n","    return features\n","\n","def split_image(image, patch_size=400, overlap=0.5):\n","    height, width = image.shape[:2]\n","    step = int(patch_size * (1 - overlap))\n","    patches, coordinates = [], []\n","    for y in range(0, height - patch_size + 1, step):\n","        for x in range(0, width - patch_size + 1, step):\n","            patches.append(image[y:y + patch_size, x:x + patch_size])\n","            coordinates.append((x, y, x + patch_size, y + patch_size))\n","    return patches, coordinates\n","\n","# Improved training with standardization\n","def train_logistic_regression(reference_folder):\n","    features, labels = [], []\n","\n","    for label in ['positive', 'negative']:\n","        folder = os.path.join(reference_folder, label)\n","        for file in os.listdir(folder):\n","            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n","                img_path = os.path.join(folder, file)\n","                img = cv2.imread(img_path)\n","                if img is not None:\n","                    features.append(extract_features(img))\n","                    labels.append(1 if label == 'positive' else 0)\n","\n","    # Standardize features\n","    scaler = StandardScaler()\n","    features = scaler.fit_transform(features)\n","\n","    # Train with class weights to handle imbalance\n","    model = LogisticRegression(max_iter=1000, class_weight='balanced', C=0.1)\n","    model.fit(features, labels)\n","\n","    # Save both model and scaler\n","    joblib.dump({'model': model, 'scaler': scaler}, 'arecanut_logistic_model.pkl')\n","    return model, scaler\n","\n","# Advanced box processing\n","def process_boxes(boxes, min_area=5000, overlap_thresh=0.3):\n","    if not boxes:\n","        return []\n","\n","    # Filter small boxes\n","    boxes = [box for box in boxes if (box[2]-box[0])*(box[3]-box[1]) > min_area]\n","\n","    # Remove nested boxes\n","    to_remove = set()\n","    for i, box1 in enumerate(boxes):\n","        for j, box2 in enumerate(boxes):\n","            if i != j and box1[0] >= box2[0] and box1[1] >= box2[1] and \\\n","               box1[2] <= box2[2] and box1[3] <= box2[3]:\n","                to_remove.add(i)\n","\n","    boxes = [box for i, box in enumerate(boxes) if i not in to_remove]\n","\n","    # Convert to numpy array for processing\n","    boxes = np.array(boxes)\n","    if len(boxes) == 0:\n","        return []\n","\n","    # Non-maximum suppression\n","    pick = []\n","    x1 = boxes[:, 0]\n","    y1 = boxes[:, 1]\n","    x2 = boxes[:, 2]\n","    y2 = boxes[:, 3]\n","\n","    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n","    idxs = np.argsort(y2)\n","\n","    while len(idxs) > 0:\n","        last = len(idxs) - 1\n","        i = idxs[last]\n","        pick.append(i)\n","\n","        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n","        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n","        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n","        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n","\n","        w = np.maximum(0, xx2 - xx1 + 1)\n","        h = np.maximum(0, yy2 - yy1 + 1)\n","\n","        overlap = (w * h) / area[idxs[:last]]\n","\n","        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlap_thresh)[0])))\n","\n","    return boxes[pick].tolist()\n","\n","# Enhanced detection with confidence\n","def detect_arecanut(image, model, scaler, patch_size=400, overlap=0.5, confidence_thresh=0.7):\n","    patches, coords = split_image(image, patch_size, overlap)\n","    boxes = []\n","    confidences = []\n","\n","    for patch, coord in zip(patches, coords):\n","        feat = extract_features(patch)\n","        feat = scaler.transform([feat])\n","        prob = model.predict_proba(feat)[0][1]\n","\n","        if prob >= confidence_thresh:\n","            boxes.append(coord)\n","            confidences.append(prob)\n","\n","    # Filter based on confidence\n","    if len(confidences) > 0:\n","        median_conf = np.median(confidences)\n","        boxes = [box for box, conf in zip(boxes, confidences) if conf >= median_conf]\n","\n","    return process_boxes(boxes)\n","\n","def save_results(image, boxes, image_name, output_image_folder, output_label_folder):\n","    os.makedirs(output_image_folder, exist_ok=True)\n","    os.makedirs(output_label_folder, exist_ok=True)\n","\n","    # Draw boxes on image\n","    output_img = image.copy()\n","    for box in boxes:\n","        x1, y1, x2, y2 = box\n","        cv2.rectangle(output_img, (x1, y1), (x2, y2), (0, 255, 0), 3)\n","\n","    # Save image with boxes\n","    cv2.imwrite(os.path.join(output_image_folder, image_name), output_img)\n","\n","    # Save labels in YOLO format\n","    h, w = image.shape[:2]\n","    label_path = os.path.join(output_label_folder, os.path.splitext(image_name)[0] + '.txt')\n","    with open(label_path, 'w') as f:\n","        for box in boxes:\n","            x_center = ((box[0] + box[2]) / 2) / w\n","            y_center = ((box[1] + box[3]) / 2) / h\n","            width = (box[2] - box[0]) / w\n","            height = (box[3] - box[1]) / h\n","            f.write(f\"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n","\n"],"metadata":{"id":"SaxazYAUyo4V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    # Model paths\n","    model_path = 'arecanut_logistic_model.pkl'\n","    reference_path = \"/content/drive/MyDrive/Arecanut_Detection_with_ML/Arecanut_Detection/Model_Statistical_Detection/reference_images\"\n","\n","    # Train or load model\n","    if not os.path.exists(model_path):\n","        print(\"Training new model...\")\n","        model, scaler = train_logistic_regression(reference_path)\n","    else:\n","        print(\"Loading pre-trained model...\")\n","        try:\n","            saved_data = joblib.load(model_path)\n","            model = saved_data['model']\n","            scaler = saved_data['scaler']\n","        except:\n","            print(\"Model format mismatch, training new model...\")\n","            model, scaler = train_logistic_regression(reference_path)\n","\n","    # Process images\n","    input_folder = \"/content/drive/MyDrive/Arecanut_Detection_with_ML/Arecanut_Detection/Model_Statistical_Detection/test_images\"\n","    output_img_folder = \"/content/drive/MyDrive/Arecanut_Detection_with_ML/Arecanut_Detection/Model_Statistical_Detection/using_logistic_regression/output_images\"\n","    output_label_folder = \"/content/drive/MyDrive/Arecanut_Detection_with_ML/Arecanut_Detection/Model_Statistical_Detection/using_logistic_regression/output_labels\"\n","\n","    os.makedirs(output_img_folder, exist_ok=True)\n","    os.makedirs(output_label_folder, exist_ok=True)\n","\n","    for img_name in sorted(os.listdir(input_folder)):\n","        if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            continue\n","\n","        img_path = os.path.join(input_folder, img_name)\n","        img = cv2.imread(img_path)\n","\n","        if img is None:\n","            print(f\"Could not read image: {img_name}\")\n","            continue\n","\n","        print(f\"Processing {img_name}...\")\n","\n","        try:\n","            boxes = detect_arecanut(img, model, scaler)\n","            save_results(\n","                image=img,\n","                boxes=boxes,\n","                image_name=img_name,\n","                output_image_folder=output_img_folder,\n","                output_label_folder=output_label_folder\n","            )\n","            print(f\"Found {len(boxes)} plantations in {img_name}\")\n","\n","        except Exception as e:\n","            print(f\"Error processing {img_name}: {str(e)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yl4zqJJCzVMv","executionInfo":{"status":"ok","timestamp":1748866099084,"user_tz":-330,"elapsed":31878,"user":{"displayName":"Prajnavi","userId":"02418603915941783168"}},"outputId":"08d9adad-97de-4a20-c4ab-cff4e22a3b51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training new model...\n","Processing image-1.jpg...\n","Found 1 plantations in image-1.jpg\n","Processing image-100.jpg...\n","Found 1 plantations in image-100.jpg\n","Processing image-101.jpg...\n","Found 0 plantations in image-101.jpg\n","Processing image-102.jpg...\n","Found 0 plantations in image-102.jpg\n","Processing image-103.jpg...\n","Found 2 plantations in image-103.jpg\n","Processing image-108.jpg...\n","Found 2 plantations in image-108.jpg\n","Processing image-11.jpg...\n","Found 0 plantations in image-11.jpg\n","Processing image-112.jpg...\n","Found 2 plantations in image-112.jpg\n","Processing image-116.jpg...\n","Found 2 plantations in image-116.jpg\n","Processing image-117.jpg...\n","Found 2 plantations in image-117.jpg\n","Processing image-119.jpg...\n","Found 2 plantations in image-119.jpg\n","Processing image-122.jpg...\n","Found 1 plantations in image-122.jpg\n","Processing image-125.jpg...\n","Found 2 plantations in image-125.jpg\n","Processing image-126.jpg...\n","Found 2 plantations in image-126.jpg\n","Processing image-127.jpg...\n","Found 2 plantations in image-127.jpg\n","Processing image-129.jpg...\n","Found 1 plantations in image-129.jpg\n","Processing image-131.jpg...\n","Found 0 plantations in image-131.jpg\n","Processing image-132.jpg...\n","Found 2 plantations in image-132.jpg\n","Processing image-134.jpg...\n","Found 1 plantations in image-134.jpg\n","Processing image-135.jpg...\n","Found 1 plantations in image-135.jpg\n","Processing image-139.jpg...\n","Found 0 plantations in image-139.jpg\n","Processing image-140.jpg...\n","Found 1 plantations in image-140.jpg\n","Processing image-141.jpg...\n","Found 0 plantations in image-141.jpg\n","Processing image-142.jpg...\n","Found 1 plantations in image-142.jpg\n","Processing image-145.jpg...\n","Found 0 plantations in image-145.jpg\n","Processing image-146.jpg...\n","Found 0 plantations in image-146.jpg\n","Processing image-147.jpg...\n","Found 2 plantations in image-147.jpg\n","Processing image-15.jpg...\n","Found 0 plantations in image-15.jpg\n","Processing image-159.jpg...\n","Found 1 plantations in image-159.jpg\n","Processing image-162.jpg...\n","Found 1 plantations in image-162.jpg\n","Processing image-164.jpg...\n","Found 1 plantations in image-164.jpg\n","Processing image-167.jpg...\n","Found 3 plantations in image-167.jpg\n","Processing image-168.jpg...\n","Found 2 plantations in image-168.jpg\n","Processing image-17.jpg...\n","Found 1 plantations in image-17.jpg\n","Processing image-170.jpg...\n","Found 1 plantations in image-170.jpg\n","Processing image-172.jpg...\n","Found 1 plantations in image-172.jpg\n","Processing image-173.jpg...\n","Found 0 plantations in image-173.jpg\n","Processing image-174.jpg...\n","Found 1 plantations in image-174.jpg\n","Processing image-175.jpg...\n","Found 0 plantations in image-175.jpg\n","Processing image-178.jpg...\n","Found 2 plantations in image-178.jpg\n","Processing image-179.jpg...\n","Found 1 plantations in image-179.jpg\n","Processing image-18.jpg...\n","Found 1 plantations in image-18.jpg\n","Processing image-19.jpg...\n","Found 2 plantations in image-19.jpg\n","Processing image-20.jpg...\n","Found 1 plantations in image-20.jpg\n","Processing image-22.jpg...\n","Found 1 plantations in image-22.jpg\n","Processing image-23.jpg...\n","Found 2 plantations in image-23.jpg\n","Processing image-24.jpg...\n","Found 1 plantations in image-24.jpg\n","Processing image-25.jpg...\n","Found 0 plantations in image-25.jpg\n","Processing image-255.jpg...\n","Found 3 plantations in image-255.jpg\n","Processing image-26.jpg...\n","Found 1 plantations in image-26.jpg\n","Processing image-27.jpg...\n","Found 1 plantations in image-27.jpg\n","Processing image-28.jpg...\n","Found 0 plantations in image-28.jpg\n","Processing image-29.jpg...\n","Found 0 plantations in image-29.jpg\n","Processing image-30.jpg...\n","Found 1 plantations in image-30.jpg\n","Processing image-302.jpg...\n","Found 2 plantations in image-302.jpg\n","Processing image-304.jpg...\n","Found 1 plantations in image-304.jpg\n","Processing image-308.jpg...\n","Found 1 plantations in image-308.jpg\n","Processing image-309.jpg...\n","Found 2 plantations in image-309.jpg\n","Processing image-31.jpg...\n","Found 0 plantations in image-31.jpg\n","Processing image-311.jpg...\n","Found 1 plantations in image-311.jpg\n","Processing image-312.jpg...\n","Found 1 plantations in image-312.jpg\n","Processing image-313.jpg...\n","Found 3 plantations in image-313.jpg\n","Processing image-315.jpg...\n","Found 1 plantations in image-315.jpg\n","Processing image-317.jpg...\n","Found 3 plantations in image-317.jpg\n","Processing image-318.jpg...\n","Found 1 plantations in image-318.jpg\n","Processing image-319.jpg...\n","Found 1 plantations in image-319.jpg\n","Processing image-32.jpg...\n","Found 2 plantations in image-32.jpg\n","Processing image-320.jpg...\n","Found 1 plantations in image-320.jpg\n","Processing image-322.jpg...\n","Found 1 plantations in image-322.jpg\n","Processing image-324.jpg...\n","Found 2 plantations in image-324.jpg\n","Processing image-33.jpg...\n","Found 1 plantations in image-33.jpg\n","Processing image-331.jpg...\n","Found 0 plantations in image-331.jpg\n","Processing image-342.jpg...\n","Found 1 plantations in image-342.jpg\n","Processing image-344.jpg...\n","Found 2 plantations in image-344.jpg\n","Processing image-345.jpg...\n","Found 2 plantations in image-345.jpg\n","Processing image-346 (1).jpg...\n","Found 2 plantations in image-346 (1).jpg\n","Processing image-346.jpg...\n","Found 2 plantations in image-346.jpg\n","Processing image-347.jpg...\n","Found 1 plantations in image-347.jpg\n","Processing image-348.jpg...\n","Found 1 plantations in image-348.jpg\n","Processing image-35.jpg...\n","Found 2 plantations in image-35.jpg\n","Processing image-350.jpg...\n","Found 1 plantations in image-350.jpg\n","Processing image-351.jpg...\n","Found 1 plantations in image-351.jpg\n","Processing image-353.jpg...\n","Found 1 plantations in image-353.jpg\n","Processing image-357.jpg...\n","Found 3 plantations in image-357.jpg\n","Processing image-360.jpg...\n","Found 1 plantations in image-360.jpg\n","Processing image-374.jpg...\n","Found 2 plantations in image-374.jpg\n","Processing image-376.jpg...\n","Found 1 plantations in image-376.jpg\n","Processing image-38.jpg...\n","Found 1 plantations in image-38.jpg\n","Processing image-382.jpg...\n","Found 0 plantations in image-382.jpg\n","Processing image-383.jpg...\n","Found 0 plantations in image-383.jpg\n","Processing image-389.jpg...\n","Found 2 plantations in image-389.jpg\n","Processing image-390.jpg...\n","Found 1 plantations in image-390.jpg\n","Processing image-4.jpg...\n","Found 2 plantations in image-4.jpg\n","Processing image-41.jpg...\n","Found 3 plantations in image-41.jpg\n","Processing image-43.jpg...\n","Found 1 plantations in image-43.jpg\n","Processing image-44.jpg...\n","Found 2 plantations in image-44.jpg\n","Processing image-45.jpg...\n","Found 3 plantations in image-45.jpg\n","Processing image-46.jpg...\n","Found 1 plantations in image-46.jpg\n","Processing image-47.jpg...\n","Found 1 plantations in image-47.jpg\n","Processing image-49.jpg...\n","Found 1 plantations in image-49.jpg\n","Processing image-50.jpg...\n","Found 0 plantations in image-50.jpg\n","Processing image-51.jpg...\n","Found 1 plantations in image-51.jpg\n","Processing image-53.jpg...\n","Found 1 plantations in image-53.jpg\n","Processing image-55.jpg...\n","Found 2 plantations in image-55.jpg\n","Processing image-6.jpg...\n","Found 0 plantations in image-6.jpg\n","Processing image-66.jpg...\n","Found 1 plantations in image-66.jpg\n","Processing image-67.jpg...\n","Found 0 plantations in image-67.jpg\n","Processing image-69.jpg...\n","Found 0 plantations in image-69.jpg\n","Processing image-7.jpg...\n","Found 1 plantations in image-7.jpg\n","Processing image-70.jpg...\n","Found 0 plantations in image-70.jpg\n","Processing image-71.jpg...\n","Found 1 plantations in image-71.jpg\n","Processing image-73.jpg...\n","Found 2 plantations in image-73.jpg\n","Processing image-78.jpg...\n","Found 1 plantations in image-78.jpg\n","Processing image-79.jpg...\n","Found 1 plantations in image-79.jpg\n","Processing image-80.jpg...\n","Found 1 plantations in image-80.jpg\n","Processing image-81.jpg...\n","Found 1 plantations in image-81.jpg\n","Processing image-82.jpg...\n","Found 1 plantations in image-82.jpg\n","Processing image-84.jpg...\n","Found 1 plantations in image-84.jpg\n","Processing image-85.jpg...\n","Found 2 plantations in image-85.jpg\n","Processing image-86.jpg...\n","Found 0 plantations in image-86.jpg\n","Processing image-96.jpg...\n","Found 0 plantations in image-96.jpg\n","Processing image-98.jpg...\n","Found 0 plantations in image-98.jpg\n","Processing image1.jpg...\n","Found 1 plantations in image1.jpg\n","Processing image2.jpg...\n","Found 1 plantations in image2.jpg\n","Processing image3.jpg...\n","Found 1 plantations in image3.jpg\n","Processing image4.jpg...\n","Found 1 plantations in image4.jpg\n","Processing image5.jpg...\n","Found 1 plantations in image5.jpg\n","Processing image6.jpg...\n","Found 2 plantations in image6.jpg\n","Processing image7.jpg...\n","Found 1 plantations in image7.jpg\n","Processing image8.jpg...\n","Found 2 plantations in image8.jpg\n"]}]}]}