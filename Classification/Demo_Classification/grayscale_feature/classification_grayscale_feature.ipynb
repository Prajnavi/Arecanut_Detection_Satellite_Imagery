{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOWcqXr+QP22NeSN875rPcW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd"],"metadata":{"id":"j5GAojlC2rUx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qneOrTms1qcE","executionInfo":{"status":"ok","timestamp":1744282056665,"user_tz":-330,"elapsed":24722,"user":{"displayName":"Prajnavi","userId":"02418603915941783168"}},"outputId":"1e8d1ab4-d80c-4e52-b330-7eafcca65276"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"code","source":["OUTPUT_FOLDER = \"/content/gdrive/MyDrive/Arecanut_Detection_with_ML/Classification/Demo_Classification/grayscale_feature/labelled_images\"\n","os.makedirs(OUTPUT_FOLDER, exist_ok=True)"],"metadata":{"id":"hfKPIlEH2CrB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading stored reference features from CSV\n","def load_reference_features(csv_file):\n","    return pd.read_csv(csv_file, header=None).values.flatten()"],"metadata":{"id":"HWHEB7U525xZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extracting features from an image\n","def extract_features(image_path):\n","    img = cv2.imread(image_path)\n","    if img is None:\n","        print(f\"Error: Could not load image {image_path}\")\n","        return None\n","\n","    img = cv2.resize(img, (128, 128))  # Resize for consistency\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    # GLCM Texture Features\n","    from skimage.feature import graycomatrix, graycoprops # Import graycomatrix and graycoprops\n","    glcm = graycomatrix(gray, distances=[5], angles=[0], symmetric=True, normed=True)\n","    contrast = graycoprops(glcm, 'contrast')[0, 0]\n","    correlation = graycoprops(glcm, 'correlation')[0, 0]\n","    energy = graycoprops(glcm, 'energy')[0, 0]\n","    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n","\n","    # Compute histogram (color features)\n","    hist = cv2.calcHist([img], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]).flatten()\n","\n","    # Edge detection (Canny)\n","    edges = cv2.Canny(gray, 100, 200)\n","    edge_density = np.sum(edges) / (128 * 128)\n","\n","    # Combine features (texture + color + edge) to match the original feature extraction\n","    return np.hstack([contrast, correlation, energy, homogeneity, hist, edge_density])"],"metadata":{"id":"IA3lbrb73T82"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Classifing and rename images\n","def classify_and_rename_images(image_folder, feature_csv, output_folder, threshold=0.8):\n","    # Loading stored features from CSV\n","    reference_features = load_reference_features(feature_csv)\n","\n","    # Checking output folder exists\n","    if not os.path.exists(output_folder):\n","        os.makedirs(output_folder)\n","\n","    # Iterating over all images in the folder\n","    for filename in os.listdir(image_folder):\n","        image_path = os.path.join(image_folder, filename)\n","\n","        # Extracting features for the current image\n","        features = extract_features(image_path)\n","        if features is None:\n","            continue  # Skiping if feature extraction failed\n","\n","        # Computing similarity (Cosine Similarity)\n","        similarity = np.dot(reference_features, features) / (np.linalg.norm(reference_features) * np.linalg.norm(features))\n","\n","        # Assigning labels (threshold default =0.8)\n","        label = \"1\" if similarity >= threshold else \"0\"\n","\n","        # Renaming and saving the image\n","        new_filename = f\"{label}_{filename}\"\n","        new_path = os.path.join(output_folder, new_filename)\n","        cv2.imwrite(new_path, cv2.imread(image_path))\n","\n","        print(f\"Processed: {filename} → {new_filename} (Similarity: {similarity:.2f})\")"],"metadata":{"id":"ykMZfAIs3a2N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_folder = \"/content/gdrive/MyDrive/Arecanut_Detection_with_ML/Classification/Demo_Classification/splitted_images\"\n","feature_file = \"/content/gdrive/MyDrive/Arecanut_Detection_with_ML/Classification/Demo_Classification/grayscale_feature/extracted_grayscale_feature.csv\"\n","output_folder = \"/content/gdrive/MyDrive/Arecanut_Detection_with_ML/Classification/Demo_Classification/grayscale_feature/labelled_images\"\n","\n","# Classify images\n","classify_and_rename_images(image_folder, feature_file, output_folder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ifc1ycqN3fUc","executionInfo":{"status":"ok","timestamp":1744282093805,"user_tz":-330,"elapsed":23043,"user":{"displayName":"Prajnavi","userId":"02418603915941783168"}},"outputId":"b2288704-4a0b-416a-86c2-ea927144e8ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed: tile_0.png → 0_tile_0.png (Similarity: 0.05)\n","Processed: tile_2.png → 1_tile_2.png (Similarity: 0.96)\n","Processed: tile_1.png → 0_tile_1.png (Similarity: 0.18)\n","Processed: tile_3.png → 1_tile_3.png (Similarity: 0.95)\n","Processed: tile_4.png → 1_tile_4.png (Similarity: 0.99)\n","Processed: tile_5.png → 1_tile_5.png (Similarity: 1.00)\n","Processed: tile_6.png → 1_tile_6.png (Similarity: 1.00)\n","Processed: tile_9.png → 1_tile_9.png (Similarity: 0.88)\n","Processed: tile_8.png → 0_tile_8.png (Similarity: 0.13)\n","Processed: tile_7.png → 0_tile_7.png (Similarity: 0.30)\n","Processed: tile_10.png → 1_tile_10.png (Similarity: 0.84)\n","Processed: tile_11.png → 1_tile_11.png (Similarity: 0.97)\n","Processed: tile_12.png → 1_tile_12.png (Similarity: 0.99)\n","Processed: tile_13.png → 1_tile_13.png (Similarity: 0.99)\n","Processed: tile_14.png → 1_tile_14.png (Similarity: 0.81)\n","Processed: tile_15.png → 0_tile_15.png (Similarity: 0.38)\n","Processed: tile_17.png → 1_tile_17.png (Similarity: 0.88)\n","Processed: tile_16.png → 1_tile_16.png (Similarity: 0.89)\n","Processed: tile_18.png → 1_tile_18.png (Similarity: 0.94)\n","Processed: tile_19.png → 1_tile_19.png (Similarity: 0.99)\n","Processed: tile_21.png → 0_tile_21.png (Similarity: 0.66)\n","Processed: tile_20.png → 1_tile_20.png (Similarity: 1.00)\n","Processed: tile_22.png → 0_tile_22.png (Similarity: 0.71)\n","Processed: tile_23.png → 0_tile_23.png (Similarity: 0.79)\n","Processed: tile_25.png → 1_tile_25.png (Similarity: 0.99)\n","Processed: tile_24.png → 1_tile_24.png (Similarity: 0.93)\n","Processed: tile_26.png → 1_tile_26.png (Similarity: 1.00)\n","Processed: tile_27.png → 1_tile_27.png (Similarity: 0.97)\n"]}]}]}