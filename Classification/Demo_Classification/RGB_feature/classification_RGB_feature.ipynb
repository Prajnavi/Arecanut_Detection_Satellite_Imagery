{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPmBG4SQMAF7JpwjneXFpfT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0eohsMNxcfPV"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from skimage.feature import graycomatrix, graycoprops\n","from google.colab import drive"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zsAsmWf4cizO","executionInfo":{"status":"ok","timestamp":1743833939353,"user_tz":-330,"elapsed":4911,"user":{"displayName":"Prajnavi","userId":"02418603915941783168"}},"outputId":"704930df-7b26-4d6f-85fe-d7b8b7ce96de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["OUTPUT_FOLDER = \"/content/gdrive/MyDrive/Arecanut_Detection_with_ML/Classification/Demo_Classification/RGB_feature/labelled_images\"\n","os.makedirs(OUTPUT_FOLDER, exist_ok=True)"],"metadata":{"id":"UysBl5ECctBo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading stored reference features from CSV\n","def load_reference_features(csv_file):\n","    return pd.read_csv(csv_file, header=None).values.flatten()"],"metadata":{"id":"LP8jywPac6h5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to extract texture and color features\n","def extract_features(image_path, distance=5):\n","    img = cv2.imread(image_path)\n","\n","    # Check if the image is there\n","    if img is None:\n","        print(f\"Error: Could not load image from {image_path}\")\n","        return None  # Or handle the error appropriately\n","\n","    img = cv2.resize(img, (128, 128))  # Resize for consistency\n","\n","    # Use green channel (index 1 in BGR) instead of converting to grayscale\n","    green_channel = img[:, :, 1]  # BGR format in OpenCV, 1 is green\n","\n","    # GLCM Texture Features using green channel\n","    glcm = graycomatrix(green_channel, distances=[distance], angles=[0], symmetric=True, normed=True)\n","    contrast = graycoprops(glcm, 'contrast')[0, 0]\n","    correlation = graycoprops(glcm, 'correlation')[0, 0]\n","    energy = graycoprops(glcm, 'energy')[0, 0]\n","    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n","\n","    # Color Histogram Features (RGB)\n","    hist = cv2.calcHist([img], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]).flatten()\n","\n","    # Edge Detection (Canny) using green channel\n","    edges = cv2.Canny(green_channel, 100, 200)\n","    edge_density = np.sum(edges) / (128 * 128)  # Ratio of edge pixels\n","\n","    return np.hstack([contrast, correlation, energy, homogeneity, hist, edge_density])\n","\n","# Test with different distance values\n","def test_distances(image_path):\n","    distances = [1, 3, 5, 7, 10]  # Different distance values to test\n","    results = {}\n","\n","    for dist in distances:\n","        features = extract_features(image_path, distance=dist)\n","        if features is not None:\n","            results[dist] = {\n","                'contrast': features[0],\n","                'correlation': features[1],\n","                'energy': features[2],\n","                'homogeneity': features[3],\n","                'edge_density': features[-1]\n","            }\n","            print(f\"Distance {dist}:\")\n","            print(f\"Contrast: {features[0]:.4f}\")\n","            print(f\"Correlation: {features[1]:.4f}\")\n","            print(f\"Energy: {features[2]:.4f}\")\n","            print(f\"Homogeneity: {features[3]:.4f}\")\n","            print(f\"Edge Density: {features[-1]:.4f}\")\n","            print(\"--------------------\")\n","\n","    return results"],"metadata":{"id":"MS_gMQYwc-rk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_reference_features(feature_csv):\n","    try:\n","        df = pd.read_csv(feature_csv, header=None)\n","        print(\"Loaded CSV shape:\", df.shape)\n","        if df.empty:\n","            raise ValueError(\"CSV file is empty!\")\n","        features = df.values.flatten()\n","        print(\"Loaded features length:\", len(features))\n","        if len(features) != 517:\n","            raise ValueError(f\"Expected 517 features, got {len(features)}\")\n","        return features\n","    except Exception as e:\n","        print(f\"Error loading reference features: {e}\")\n","        return None\n","\n","def classify_and_rename_images(image_folder, feature_csv, output_folder, threshold=0.8, distance=5):\n","    reference_features = load_reference_features(feature_csv)\n","    if reference_features is None:\n","        print(\"Aborting classification due to reference feature loading failure!\")\n","        return\n","\n","    if not os.path.exists(output_folder):\n","        os.makedirs(output_folder)\n","\n","    for filename in os.listdir(image_folder):\n","        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n","            image_path = os.path.join(image_folder, filename)\n","            features = extract_features(image_path, distance=distance)\n","            if features is None:\n","                print(f\"Skipping {filename} - feature extraction failed\")\n","                continue\n","\n","            try:\n","                similarity = np.dot(reference_features, features) / (\n","                    np.linalg.norm(reference_features) * np.linalg.norm(features)\n","                )\n","                label = \"1\" if similarity >= threshold else \"0\"\n","                new_filename = f\"{label}_{filename}\"\n","                new_path = os.path.join(output_folder, new_filename)\n","                img = cv2.imread(image_path)\n","                if img is not None:\n","                    cv2.imwrite(new_path, img)\n","                    print(f\"Processed: {filename} → {new_filename} (Similarity: {similarity:.2f})\")\n","                else:\n","                    print(f\"Failed to read image: {filename}\")\n","            except ValueError as e:\n","                print(f\"Error computing similarity for {filename}: {e}\")\n","\n","# Paths\n","image_folder = \"/content/gdrive/MyDrive/Arecanut_Detection_with_ML/Classification/Demo_Classification/splitted_images\"\n","feature_file = \"/content/gdrive/MyDrive/Arecanut_Detection_with_ML/Classification/Demo_Classification/RGB_feature/extracted_RGB_feature.csv\"\n","output_folder = \"/content/gdrive/MyDrive/Arecanut_Detection_with_ML/Classification/Demo_Classification/RGB_feature/labelled_images\"\n","\n","# Classify images\n","classify_and_rename_images(image_folder, feature_file, output_folder, threshold=0.8, distance=5)\n","\n","# Sync Drive\n","drive.flush_and_unmount()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wbwiKyxxiyTl","executionInfo":{"status":"ok","timestamp":1743833975224,"user_tz":-330,"elapsed":18900,"user":{"displayName":"Prajnavi","userId":"02418603915941783168"}},"outputId":"0ccea42f-b6dd-4b72-810b-e7023169613a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded CSV shape: (1, 517)\n","Loaded features length: 517\n","Processed: tile_9.png → 1_tile_9.png (Similarity: 0.89)\n","Processed: tile_6.png → 1_tile_6.png (Similarity: 1.00)\n","Processed: tile_12.png → 1_tile_12.png (Similarity: 0.99)\n","Processed: tile_23.png → 0_tile_23.png (Similarity: 0.79)\n","Processed: tile_27.png → 1_tile_27.png (Similarity: 0.97)\n","Processed: tile_26.png → 1_tile_26.png (Similarity: 1.00)\n","Processed: tile_3.png → 1_tile_3.png (Similarity: 0.96)\n","Processed: tile_17.png → 1_tile_17.png (Similarity: 0.89)\n","Processed: tile_25.png → 1_tile_25.png (Similarity: 0.99)\n","Processed: tile_0.png → 0_tile_0.png (Similarity: 0.05)\n","Processed: tile_13.png → 1_tile_13.png (Similarity: 0.99)\n","Processed: tile_2.png → 1_tile_2.png (Similarity: 0.97)\n","Processed: tile_16.png → 1_tile_16.png (Similarity: 0.90)\n","Processed: tile_21.png → 0_tile_21.png (Similarity: 0.66)\n","Processed: tile_19.png → 1_tile_19.png (Similarity: 0.99)\n","Processed: tile_15.png → 0_tile_15.png (Similarity: 0.39)\n","Processed: tile_8.png → 0_tile_8.png (Similarity: 0.14)\n","Processed: tile_24.png → 1_tile_24.png (Similarity: 0.94)\n","Processed: tile_4.png → 1_tile_4.png (Similarity: 0.99)\n","Processed: tile_18.png → 1_tile_18.png (Similarity: 0.95)\n","Processed: tile_22.png → 0_tile_22.png (Similarity: 0.70)\n","Processed: tile_7.png → 0_tile_7.png (Similarity: 0.31)\n","Processed: tile_5.png → 1_tile_5.png (Similarity: 1.00)\n","Processed: tile_11.png → 1_tile_11.png (Similarity: 0.98)\n","Processed: tile_20.png → 1_tile_20.png (Similarity: 1.00)\n","Processed: tile_10.png → 1_tile_10.png (Similarity: 0.85)\n","Processed: tile_14.png → 1_tile_14.png (Similarity: 0.82)\n","Processed: tile_1.png → 0_tile_1.png (Similarity: 0.20)\n"]}]}]}